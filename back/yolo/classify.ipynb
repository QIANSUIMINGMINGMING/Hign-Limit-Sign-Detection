{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53f1348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:08.654890Z",
     "iopub.status.busy": "2021-04-29T15:02:08.654509Z",
     "iopub.status.idle": "2021-04-29T15:02:10.099480Z",
     "shell.execute_reply": "2021-04-29T15:02:10.098664Z",
     "shell.execute_reply.started": "2021-04-29T15:02:08.654843Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec18ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:10.101147Z",
     "iopub.status.busy": "2021-04-29T15:02:10.100909Z",
     "iopub.status.idle": "2021-04-29T15:02:10.110526Z",
     "shell.execute_reply": "2021-04-29T15:02:10.109828Z",
     "shell.execute_reply.started": "2021-04-29T15:02:10.101120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HotdogData(Dataset):\n",
    "    def __init__(self, img_path, transforms=None):\n",
    "        # 初始化，读取数据集\n",
    "        self.transforms = transforms\n",
    "        self.img_path = img_path\n",
    "        self.pos_dir = img_path + '/height-limit'\n",
    "        self.neg_dir = img_path + '/not-height-limit'\n",
    "        self.pos_dirs = os.listdir(self.pos_dir)\n",
    "        self.neg_dirs = os.listdir(self.neg_dir)\n",
    "        self.pos_num = len(self.pos_dirs)\n",
    "        self.neg_num = len(self.neg_dirs)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.pos_num + self.neg_num\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index < self.pos_num: # 获取正样本\n",
    "            label = 1\n",
    "#             path=self.pos_dir + '/' + str(index) + '.png'\n",
    "#             print(path)\n",
    "            img = Image.open(self.pos_dir + '/' + self.pos_dirs[index])\n",
    "        else: # 获取负样本\n",
    "            label = 0\n",
    "            img = Image.open(self.neg_dir + '/' + self.neg_dirs[index-self.pos_num])\n",
    "            \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874353dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:10.111797Z",
     "iopub.status.busy": "2021-04-29T15:02:10.111572Z",
     "iopub.status.idle": "2021-04-29T15:02:11.032718Z",
     "shell.execute_reply": "2021-04-29T15:02:11.031326Z",
     "shell.execute_reply.started": "2021-04-29T15:02:10.111772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)), # 将图像随意裁剪，宽高均为224\n",
    "                    transforms.RandomHorizontalFlip(), # 以0.5的概率左右翻转图像\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "#                     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0),\n",
    "                    transforms.RandomRotation(degrees=5, expand=False, fill=None),\n",
    "                    transforms.ToTensor(), # 将PIL图像转为Tensor，并且进行归一化\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 标准化\n",
    "                ])\n",
    "test_transform = transforms.Compose([\n",
    "                    transforms.Resize(256), \n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(), # 将PIL图像转为Tensor，并且进行归一化\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 标准化\n",
    "                ])\n",
    "\n",
    "train_data = HotdogData('/openbayes/input/input0/classification-train', transforms=train_transform)\n",
    "trainloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "test_data = HotdogData('/openbayes/input/input0/classification-test', transforms=test_transform)\n",
    "testloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fd137f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:11.035301Z",
     "iopub.status.busy": "2021-04-29T15:02:11.034834Z",
     "iopub.status.idle": "2021-04-29T15:02:16.152848Z",
     "shell.execute_reply": "2021-04-29T15:02:16.151545Z",
     "shell.execute_reply.started": "2021-04-29T15:02:11.035248Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = models.resnet18(pretrained=True, progress=True)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d831e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:16.154716Z",
     "iopub.status.busy": "2021-04-29T15:02:16.154489Z",
     "iopub.status.idle": "2021-04-29T15:02:16.693870Z",
     "shell.execute_reply": "2021-04-29T15:02:16.693038Z",
     "shell.execute_reply.started": "2021-04-29T15:02:16.154687Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(13, 3, 224, 224).cuda()\n",
    "with SummaryWriter('runs/exp-1') as w:\n",
    "    w.add_graph(net, (dummy_input,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43ec40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:16.695187Z",
     "iopub.status.busy": "2021-04-29T15:02:16.695003Z",
     "iopub.status.idle": "2021-04-29T15:02:16.699254Z",
     "shell.execute_reply": "2021-04-29T15:02:16.698676Z",
     "shell.execute_reply.started": "2021-04-29T15:02:16.695167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 全连接层的输入通道in_channels个数\n",
    "num_fc_in = net.fc.in_features\n",
    "\n",
    "# 改变全连接层，2分类问题，out_features = 2\n",
    "net.fc = nn.Linear(num_fc_in, 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d2dab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:16.700969Z",
     "iopub.status.busy": "2021-04-29T15:02:16.700796Z",
     "iopub.status.idle": "2021-04-29T15:02:16.710491Z",
     "shell.execute_reply": "2021-04-29T15:02:16.709353Z",
     "shell.execute_reply.started": "2021-04-29T15:02:16.700950Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6874ddf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:16.712902Z",
     "iopub.status.busy": "2021-04-29T15:02:16.712487Z",
     "iopub.status.idle": "2021-04-29T15:02:16.723350Z",
     "shell.execute_reply": "2021-04-29T15:02:16.722633Z",
     "shell.execute_reply.started": "2021-04-29T15:02:16.712855Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001 / 10\n",
    "fc_params = list(map(id, net.fc.parameters())) # 取得全连接层的参数内存地址的列表\n",
    "base_params = filter(lambda p: id(p) not in fc_params, net.parameters()) # 取得其他层参数的列表\n",
    "optimizer = optim.Adam([\n",
    "            {'params': base_params},\n",
    "            {'params': net.fc.parameters(), 'lr': lr * 10}],\n",
    "            lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf93450d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:02:16.724594Z",
     "iopub.status.busy": "2021-04-29T15:02:16.724371Z",
     "iopub.status.idle": "2021-04-29T15:48:50.581047Z",
     "shell.execute_reply": "2021-04-29T15:48:50.579658Z",
     "shell.execute_reply.started": "2021-04-29T15:02:16.724569Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     5] loss: 0.410\n",
      "[0,    10] loss: 0.038\n",
      "[0,    15] loss: 0.078\n",
      "[0,    20] loss: 0.063\n",
      "[0,    25] loss: 0.054\n",
      "[0,    30] loss: 0.070\n",
      "[0,    35] loss: 0.037\n",
      "[0,    40] loss: 0.040\n",
      "[0,    45] loss: 0.011\n",
      "[0,    50] loss: 0.005\n",
      "[0,    55] loss: 0.018\n",
      "[0,    60] loss: 0.019\n",
      "[0,    65] loss: 0.006\n",
      "[0,    70] loss: 0.005\n",
      "[0,    75] loss: 0.005\n",
      "[0,    80] loss: 0.006\n",
      "[0,    85] loss: 0.016\n",
      "[0,    90] loss: 0.004\n",
      "[0,    95] loss: 0.003\n",
      "[0,   100] loss: 0.002\n",
      "[0,   105] loss: 0.004\n",
      "[0,   110] loss: 0.003\n",
      "[0,   115] loss: 0.001\n",
      "[0,   120] loss: 0.009\n",
      "[0,   125] loss: 0.009\n",
      "[0,   130] loss: 0.013\n",
      "[0,   135] loss: 0.003\n",
      "[0,   140] loss: 0.003\n",
      "[0,   145] loss: 0.019\n",
      "[0,   150] loss: 0.003\n",
      "[0,   155] loss: 0.024\n",
      "[0,   160] loss: 0.004\n",
      "[0,   165] loss: 0.022\n",
      "[0,   170] loss: 0.005\n",
      "[0,   175] loss: 0.003\n",
      "[0,   180] loss: 0.005\n",
      "[0,   185] loss: 0.009\n",
      "[0,   190] loss: 0.002\n",
      "[0,   195] loss: 0.001\n",
      "[0,   200] loss: 0.002\n",
      "[0,   205] loss: 0.002\n",
      "[0,   210] loss: 0.001\n",
      "[0,   215] loss: 0.014\n",
      "[0,   220] loss: 0.007\n",
      "[0,   225] loss: 0.035\n",
      "[0,   230] loss: 0.034\n",
      "[0,   235] loss: 0.007\n",
      "[0,   240] loss: 0.002\n",
      "[0,   245] loss: 0.004\n",
      "[0,   250] loss: 0.017\n",
      "[0,   255] loss: 0.001\n",
      "[1,     5] loss: 0.001\n",
      "[1,    10] loss: 0.001\n",
      "[1,    15] loss: 0.022\n",
      "[1,    20] loss: 0.002\n",
      "[1,    25] loss: 0.005\n",
      "[1,    30] loss: 0.002\n",
      "[1,    35] loss: 0.009\n",
      "[1,    40] loss: 0.001\n",
      "[1,    45] loss: 0.001\n",
      "[1,    50] loss: 0.001\n",
      "[1,    55] loss: 0.005\n",
      "[1,    60] loss: 0.002\n",
      "[1,    65] loss: 0.001\n",
      "[1,    70] loss: 0.001\n",
      "[1,    75] loss: 0.001\n",
      "[1,    80] loss: 0.001\n",
      "[1,    85] loss: 0.003\n",
      "[1,    90] loss: 0.001\n",
      "[1,    95] loss: 0.024\n",
      "[1,   100] loss: 0.002\n",
      "[1,   105] loss: 0.002\n",
      "[1,   110] loss: 0.012\n",
      "[1,   115] loss: 0.007\n",
      "[1,   120] loss: 0.000\n",
      "[1,   125] loss: 0.001\n",
      "[1,   130] loss: 0.000\n",
      "[1,   135] loss: 0.007\n",
      "[1,   140] loss: 0.014\n",
      "[1,   145] loss: 0.001\n",
      "[1,   150] loss: 0.001\n",
      "[1,   155] loss: 0.004\n",
      "[1,   160] loss: 0.001\n",
      "[1,   165] loss: 0.001\n",
      "[1,   170] loss: 0.000\n",
      "[1,   175] loss: 0.000\n",
      "[1,   180] loss: 0.003\n",
      "[1,   185] loss: 0.008\n",
      "[1,   190] loss: 0.005\n",
      "[1,   195] loss: 0.002\n",
      "[1,   200] loss: 0.001\n",
      "[1,   205] loss: 0.004\n",
      "[1,   210] loss: 0.000\n",
      "[1,   215] loss: 0.004\n",
      "[1,   220] loss: 0.016\n",
      "[1,   225] loss: 0.000\n",
      "[1,   230] loss: 0.001\n",
      "[1,   235] loss: 0.020\n",
      "[1,   240] loss: 0.007\n",
      "[1,   245] loss: 0.003\n",
      "[1,   250] loss: 0.001\n",
      "[1,   255] loss: 0.014\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 2\n",
    "evaluate_batch_num = 5\n",
    "\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).cuda()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        if i % evaluate_batch_num == evaluate_batch_num - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch, i + 1, running_loss / evaluate_batch_num))\n",
    "            \n",
    "            with SummaryWriter('runs/exp-1') as w:\n",
    "                w.add_scalar('TrainLoss/epoch' + str(epoch), running_loss / evaluate_batch_num, i // evaluate_batch_num)             \n",
    "            running_loss = 0.0\n",
    "            \n",
    "    with SummaryWriter('runs/exp-1') as w:\n",
    "        w.add_scalar('TrainLoss/all', epoch_loss / len(trainloader), epoch)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(),\"model.pt\")     \n",
    "    \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d39a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:48:50.583380Z",
     "iopub.status.busy": "2021-04-29T15:48:50.583044Z",
     "iopub.status.idle": "2021-04-29T15:52:20.058007Z",
     "shell.execute_reply": "2021-04-29T15:52:20.056809Z",
     "shell.execute_reply.started": "2021-04-29T15:48:50.583320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(63, 64)\n",
      "(tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]), tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(122, 128)\n",
      "(tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]))\n",
      "(183, 192)\n",
      "(tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]))\n",
      "(246, 256)\n",
      "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]))\n",
      "(307, 320)\n",
      "(tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(371, 384)\n",
      "(tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]), tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]))\n",
      "(433, 448)\n",
      "(tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]), tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]))\n",
      "(494, 512)\n",
      "(tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "(557, 576)\n",
      "(tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]))\n",
      "(618, 640)\n",
      "(tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]))\n",
      "(682, 704)\n",
      "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]))\n",
      "(744, 768)\n",
      "(tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]), tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(805, 832)\n",
      "(tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1]))\n",
      "(856, 888)\n",
      "Accuracy of the network on the test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net=net.cpu()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        print((labels,predicted))\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print((correct,total))\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902a4467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T15:52:20.060041Z",
     "iopub.status.busy": "2021-04-29T15:52:20.059749Z",
     "iopub.status.idle": "2021-04-29T15:52:20.658004Z",
     "shell.execute_reply": "2021-04-29T15:52:20.655541Z",
     "shell.execute_reply.started": "2021-04-29T15:52:20.060007Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/openbayes/input/input0/train/no/163.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0e1ff4787003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mim_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/openbayes/input/input0/train/no/163.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m test_transform = transforms.Compose([\n\u001b[1;32m     15\u001b[0m                     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/openbayes/input/input0/train/no/163.png'"
     ]
    }
   ],
   "source": [
    "# 载入模型并预测\n",
    "m_state_dict = torch.load('model.pt')\n",
    "new_model= models.resnet18(pretrained=False, progress=True)\n",
    "num_fc_in = new_model.fc.in_features\n",
    "\n",
    "new_model.fc = nn.Linear(num_fc_in, 2)\n",
    "\n",
    "new_model.load_state_dict(m_state_dict)\n",
    "\n",
    "new_model.eval()\n",
    "\n",
    "im_path=\"/openbayes/input/input0/train/no/163.png\"\n",
    "img=Image.open(im_path)\n",
    "test_transform = transforms.Compose([\n",
    "                    transforms.Resize(256), \n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(), # 将PIL图像转为Tensor，并且进行归一化\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 标准化\n",
    "                ])\n",
    "img_=test_transform(img).unsqueeze(0)\n",
    "\n",
    "outputs = new_model(img_)\n",
    "print(outputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(torch.max(outputs.data, 1))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c74fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
